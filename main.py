import requests
from sys import argv, exit
from tabulate import tabulate
from bs4 import BeautifulSoup

# Niektóre URL zwrócone przez BS4 nie są pełne. Tą funkcją takie adresy są naprawiane
def fix_URL(url:str,match:str):
    if match=="javascript:void(0)": return None # bs4 zwraca to jako źródło skryptu, więc należy to odrzucić
    elif match[0]=="/":
        if url[7:] in match or url[8:] in match: match="https:"+match # dodawanie protokołu do URL
        else: match=url+"/"+match # dodawanie bazowego URL
    return match

# Wyniki sa konwertowane do formatu oczekiwanego przez API
def jsonify_URL(url:str):
    entry = {"url":""}
    entry["url"] = url
    return entry

def wykryj_malware(url:str,apikey:str):
    # Link do Google Safe Browsing API V4
    api_url=f"https://safebrowsing.googleapis.com/v4/threatMatches:find?key={apikey}"

    # Przełączniki debugowe
    sprawdz_linki           = True
    sprawdz_url_skryptow    = True
    debug_drukuj_znalezione = False

    # Listy, które zostaną zapełnione znalezionymi URL-ami
    urls_scripts    = []
    urls_links      = []
    json_links      = []

    # Pobierz kod źródłowy strony
    print("Pobieranie strony...")
    r = requests.get(url)
    source = r.text

    # Przetwórz pobrany kod strony
    print("Przetwarzanie HTML...")
    soup = BeautifulSoup(source, "html.parser")

    # Zbieranie źródeł skryptów
    if sprawdz_url_skryptow:
        print("Filtrowanie URL skryptów...")
        scripts = soup.find_all("script",src=True)
        for i in scripts: 
            match=fix_URL(url,i["src"])
            if match and match not in urls_scripts: urls_scripts.append(match)
        for i in urls_scripts:
            json_links.append(jsonify_URL(i))

    # Zbieranie linków z odnośników (wszystkie <a> tagi HTML)
    if sprawdz_linki:
        print("Filtrowanie URL odnośników...")
        links = soup.find_all("a", href=True)
        for i in links:
            match=fix_URL(url,i["href"])
            if match and match not in urls_links: urls_links.append(match)
        for i in urls_links:
            json_links.append(jsonify_URL(i))

    # Zliczanie znalezionych zasobów
    print(f"Znaleziono:\n{len(urls_scripts)}\tURL skryptów\n{len(urls_links)}\tURL hiperłączy\n")

    # drukowanie znalezionych zasobów, które zostaną sprawdzone. do aktywacji przy użyciu debug switcha na górze funkcji
    if debug_drukuj_znalezione:
        for i in json_links: print(i)
        for i in urls_links: print(i)

    print("Wysyłanie znalezionych adresów URL do Google Safe Browsing...")

    # ciało żądania do wysłania Google Safe Browsing
    request_body={
        "client": {
            "clientId":         "zit-projekt-jk-kw",
            "clientVersion":    "1.0.0"
        },
        "threatInfo": {
            "threatTypes":      ["THREAT_TYPE_UNSPECIFIED","MALWARE","SOCIAL_ENGINEERING","UNWANTED_SOFTWARE","POTENTIALLY_HARMFUL_APPLICATION"],
            "platformTypes":    ["ANY_PLATFORM"],
            "threatEntryTypes": ["URL","EXECUTABLE"],
            "threatEntries": []
        }
    }

    # wklejanie znalezionych linków do pola threatEntires JSON'a
    for i in json_links:
        request_body["threatInfo"]["threatEntries"]=json_links

    # inicjalizacja
    odpowiedz = None

    if True:
        r = requests.post(url=api_url,json=request_body)
        odpowiedz = r.json()

    if odpowiedz:
        wyniki=[]
        for matches in odpowiedz["matches"]:
            wyniki.append([matches["threatType"],matches["threatEntryType"],matches["cacheDuration"],matches["threat"]])
        if wyniki: print("Co najmniej jeden zasób strony został uznany przez Google Safe Browsing jako złośliwy. Zostały one wymienione poniżej:")

        print(tabulate(wyniki,["RODZAJ","TYP WPISU","WAŻNOŚĆ CACHE","ZASÓB"]),"\n")
    else:
        print("Nie znaleziono zasobów, które zostały uznane jako złośliwe.")

    print("Powered by Google Safe Browsing API V4. ")

if __name__=="__main__": 
    match len(argv): # sprawdzanie argumentów
        case 1: # w razie braku
            print("Składnia: python main.py URL [Klucz API]\nKlucz API może zostać pominięty, jeżeli znajduje się w pliku apikey.txt w katalogu skryptu.")
            exit(1)
        case 2: # w razie podania tylko URL
            url=argv[1]
            try:
                with open("apikey.txt","r") as f: apikey=f.read()
            except FileNotFoundError: # w razie nieodnalezienia pliku
                print("""Nie znaleziono pliku apikey.txt
Klucz API można podać jako drugi argument programu, albo może zostać wklejony do pliku apikey.txt w tym samym katalogu, co skrypt.
                
Aby uzyskać klucz API do Google Safe Browsing:
1. Potrzebne jest konto Google
2. Należy założyć projekt w Google Developer Console. Instrukcje: https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=en&rd=1
3. Należy wygenerować klucz API. Instrukcje: https://cloud.google.com/docs/authentication/api-keys?hl=en&ref_topic=6262490&rd=1
4. Należy aktywować \"Safe Browsing APIs\".""")
                exit()
            except Exception as err: # w razie innego błędu przy odczytywaniu pliku
                print(f"Wystąpił nieoczekiwany błąd ({err}).")
                exit(1)
        case 3: # w razie podania dwóch argumentów
            url     = argv[1]
            apikey  = argv[2]

    wykryj_malware(url=url,apikey=apikey) # wykonywanie głównej części programu
